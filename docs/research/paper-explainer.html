<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<title>GlassBox AI - Research Paper Explainer</title>
<link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700;800&family=JetBrains+Mono:wght@400;500;600&display=swap" rel="stylesheet">
<style>
@page{size:A4;margin:0}
*{margin:0;padding:0;box-sizing:border-box}
html{scroll-behavior:smooth}
body{font-family:'Inter',sans-serif;background:#111;color:#f0f0f0;line-height:1.7}
.cover{width:100%;min-height:100vh;display:flex;flex-direction:column;align-items:center;justify-content:center;background:linear-gradient(160deg,#0f172a,#1e1b4b,#0f172a);page-break-after:always;padding:60px 48px;text-align:center}
.cover h1{font-size:3.2rem;font-weight:800;background:linear-gradient(135deg,#4ade80,#38bdf8,#c084fc);-webkit-background-clip:text;background-clip:text;-webkit-text-fill-color:transparent;margin-bottom:12px}
.cover .sub{font-size:1.05rem;color:#94a3b8;font-weight:300;letter-spacing:2px;margin-bottom:56px}
.toc{text-align:left;max-width:640px;width:100%}
.ts{margin-bottom:22px} .ts h3{font-size:.7rem;letter-spacing:3px;text-transform:uppercase;margin-bottom:8px;font-weight:700}
.ts a{display:block;font-size:.88rem;color:#cbd5e1;padding:5px 0 5px 28px;text-decoration:none;transition:color .2s}
.ts a:hover{color:#fff;text-decoration:underline}
.ts a .n{color:#64748b;font-family:'JetBrains Mono',monospace;font-size:.78rem;margin-right:8px}
.sg h3{color:#4ade80} .sb h3{color:#60a5fa} .sy h3{color:#fbbf24} .sp h3{color:#c084fc} .sr h3{color:#f87171}
.cover .ft{margin-top:56px;font-size:.68rem;color:#475569;letter-spacing:1px}
.paper{width:100%;min-height:100vh;padding:52px 60px 40px;page-break-after:always;position:relative}
.tb{height:5px;position:absolute;top:0;left:0;right:0}
.cg{background:#0c1a0c} .cg .tb{background:linear-gradient(90deg,#4ade80,#16a34a)} .cg .ac{color:#4ade80} .cg .ib{background:#16a34a22;border:2px solid #4ade80} .cg .dg{border-color:#4ade8044;background:#4ade8008} .cg .tk{background:#4ade8012;border-left:4px solid #4ade80} .cg .lb{border-color:#4ade8033}
.cb{background:#0c0c1a} .cb .tb{background:linear-gradient(90deg,#60a5fa,#2563eb)} .cb .ac{color:#60a5fa} .cb .ib{background:#2563eb22;border:2px solid #60a5fa} .cb .dg{border-color:#60a5fa44;background:#60a5fa08} .cb .tk{background:#60a5fa12;border-left:4px solid #60a5fa} .cb .lb{border-color:#60a5fa33}
.cy{background:#1a180c} .cy .tb{background:linear-gradient(90deg,#fbbf24,#d97706)} .cy .ac{color:#fbbf24} .cy .ib{background:#d9770622;border:2px solid #fbbf24} .cy .dg{border-color:#fbbf2444;background:#fbbf2408} .cy .tk{background:#fbbf2412;border-left:4px solid #fbbf24} .cy .lb{border-color:#fbbf2433}
.cp{background:#140c1a} .cp .tb{background:linear-gradient(90deg,#c084fc,#9333ea)} .cp .ac{color:#c084fc} .cp .ib{background:#9333ea22;border:2px solid #c084fc} .cp .dg{border-color:#c084fc44;background:#c084fc08} .cp .tk{background:#c084fc12;border-left:4px solid #c084fc} .cp .lb{border-color:#c084fc33}
.cr{background:#1a0c0c} .cr .tb{background:linear-gradient(90deg,#f87171,#dc2626)} .cr .ac{color:#f87171} .cr .ib{background:#dc262622;border:2px solid #f87171} .cr .dg{border-color:#f8717144;background:#f8717108} .cr .tk{background:#f8717112;border-left:4px solid #f87171} .cr .lb{border-color:#f8717133}
.ph{display:flex;align-items:flex-start;gap:20px;margin-bottom:28px}
.ib{font-size:2.2rem;width:60px;height:60px;display:flex;align-items:center;justify-content:center;border-radius:14px;flex-shrink:0}
.pt{font-size:1.4rem;font-weight:800;line-height:1.3;color:#fff;margin-bottom:4px}
.pa{font-size:.78rem;color:#94a3b8} .pa a{color:#94a3b8;text-decoration:none;border-bottom:1px dotted #64748b} .pa a:hover{color:#e2e8f0}
.ps{font-size:.75rem;margin-top:4px}
.sl{font-size:.62rem;letter-spacing:3px;text-transform:uppercase;color:#64748b;margin-top:22px;margin-bottom:8px;font-weight:600}
.an{font-size:.9rem;color:#e2e8f0;padding:14px 18px;border-left:3px solid #475569;margin:8px 0;background:rgba(255,255,255,.03);border-radius:0 10px 10px 0;line-height:1.7}
.dg{font-family:'JetBrains Mono',monospace;font-size:.76rem;padding:18px 22px;border-radius:12px;border:1px solid;margin:12px 0;line-height:1.9;white-space:pre;overflow-x:auto;color:#e2e8f0}
.tk{font-size:.92rem;color:#f1f5f9;padding:14px 18px;border-radius:0 10px 10px 0;margin:10px 0;font-weight:500;line-height:1.7}
.lb{font-size:.8rem;color:#94a3b8;margin-top:20px;padding-top:14px;border-top:1px solid}
.lb strong{color:#4ade80;font-weight:700}
.pg{position:absolute;bottom:22px;right:44px;font-size:.6rem;color:#334155;font-family:'JetBrains Mono',monospace}
p{font-size:.88rem;color:#cbd5e1;margin:5px 0}
.ck{background:#0f172a} .ck .tb{background:linear-gradient(90deg,#4ade80,#38bdf8,#c084fc)}
.ck-t{font-size:1.6rem;font-weight:800;color:#fff;margin-bottom:8px}
.ck-s{font-size:.85rem;color:#94a3b8;margin-bottom:32px}
.ck-row{display:flex;align-items:flex-start;gap:14px;padding:10px 0;border-bottom:1px solid #1e293b;font-size:.85rem;color:#cbd5e1}
.ck-row .ck-chk{font-size:1.1rem;flex-shrink:0;width:24px}
.ck-row .ck-paper{font-weight:600;color:#fff;min-width:200px}
.ck-row .ck-what{color:#94a3b8;flex:1}
</style>
</head>
<body>

<!-- COVER -->
<div class="cover">
<h1>Research Paper Explainer</h1>
<div class="sub">16 papers that power GlassBox AI - explained visually</div>
<div class="toc">
<div class="ts sg"><h3>ğŸ§  Multi-Agent Debate</h3>
<a href="#p01"><span class="n">01</span> Multi-Agent Debate for Factuality (Du et al.)</a>
<a href="#p02"><span class="n">02</span> ChatEval: Debate for Evaluation (Chan et al.)</a>
<a href="#p03"><span class="n">03</span> Society of Mind for LLMs (Zhang et al.)</a>
<a href="#p04"><span class="n">04</span> Tree of Thoughts (Yao et al.)</a></div>
<div class="ts sb"><h3>ğŸ”’ Trust &amp; Reputation</h3>
<a href="#p05"><span class="n">05</span> EigenTrust: PageRank for Trust (Kamvar et al.)</a>
<a href="#p06"><span class="n">06</span> Trust Models Survey (Pinyol &amp; Sabater-Mir)</a>
<a href="#p07"><span class="n">07</span> Cognitive vs Emotional Trust (Shang et al.)</a>
<a href="#p08"><span class="n">08</span> LLM-as-a-Judge Survey (Li et al.)</a></div>
<div class="ts sy"><h3>ğŸ” Grounding &amp; Fact-Checking</h3>
<a href="#p09"><span class="n">09</span> FACTS Grounding Benchmark (Google DeepMind)</a>
<a href="#p10"><span class="n">10</span> MiniCheck: Cheap Fact-Checking (Tang et al.)</a></div>
<div class="ts sp"><h3>ğŸ”„ Self-Correction &amp; Refinement</h3>
<a href="#p11"><span class="n">11</span> Self-Refine (Madaan et al.)</a>
<a href="#p12"><span class="n">12</span> Reflexion: Verbal RL (Shinn et al.)</a>
<a href="#p13"><span class="n">13</span> Self-Correct via RL (Google DeepMind)</a>
<a href="#p14"><span class="n">14</span> Code Repair as Exploration (NeurIPS 2024)</a></div>
<div class="ts sr"><h3>ğŸ›¡ï¸ AI Safety &amp; Oversight</h3>
<a href="#p15"><span class="n">15</span> AI Safety via Debate (Irving et al.)</a>
<a href="#p16"><span class="n">16</span> Constitutional AI (Bai et al., Anthropic)</a></div>
</div>
<div class="ft">agentic-trust-labs/glassbox-ai Â· February 2026</div>
</div>

<!-- 01 -->
<div class="paper cg" id="p01"><div class="tb"></div>
<div class="ph"><div class="ib">âš”ï¸</div><div>
<div class="pt">Multi-Agent Debate for Factuality</div>
<div class="pa">(Du et al.) Â· NeurIPS 2024 Â· <a href="https://arxiv.org/abs/2305.14325">arXiv:2305.14325</a></div>
<div class="ps">â­â­â­â­â­ The foundational paper</div></div></div>
<div class="sl">ğŸ­ Analogy</div>
<div class="an">A courtroom. One lawyer says "guilty," another says "innocent." The jury hears BOTH sides and decides better than either lawyer alone. This paper does that with LLMs arguing about facts.</div>
<div class="sl">ğŸ“ Diagram</div>
<div class="dg">Round 1:  Agent A â†’ "42"      Agent B â†’ "37"      Agent C â†’ "42"
Round 2:  A sees B,C â†’ "42"   B sees A,C â†’ "hmm"  C sees A,B â†’ "42"
Round 3:  A: "42 âœ…"          B: "Ok 42 âœ…"        C: "42 âœ…"
                        Converged â†’ 42 (correct!)</div>
<div class="sl">ğŸ’ The Core Trick</div>
<div class="tk">Multiple LLMs independently answer, share, debate, converge. Wrong answers don't survive cross-examination. <span class="ac">Free accuracy boost - no fine-tuning needed.</span> 10-20% improvement on math and factual QA.</div>
<div class="lb"><strong>â†’ GlassBox borrows:</strong> Our 3-round debate (Position â†’ Reaction â†’ Convergence) is a direct implementation of this insight.</div>
<div class="pg">01 / 16</div></div>

<!-- 02 -->
<div class="paper cg" id="p02"><div class="tb"></div>
<div class="ph"><div class="ib">ğŸ…</div><div>
<div class="pt">ChatEval: Debate for Evaluation</div>
<div class="pa">(Chan et al.) Â· ICLR 2024 Â· <a href="https://arxiv.org/abs/2308.07201">arXiv:2308.07201</a></div>
<div class="ps">â­â­â­â­ Debate for judging, not generating</div></div></div>
<div class="sl">ğŸ­ Analogy</div>
<div class="an">Movie critics. One says "masterpiece," another says "overrated." Their public disagreement is more informative than any single review. Readers get a nuanced picture.</div>
<div class="sl">ğŸ“ Diagram</div>
<div class="dg">"Rate this essay"  â†’  Judge 1: 7/10  "Clear structure"
                   â†’  Judge 2: 4/10  "Lacks evidence"
                   â†’  Judge 3: 8/10  "Creative angle"
                            â†“
                   Debate â†’ Agreed: 6/10 (matches human rating)</div>
<div class="sl">ğŸ’ The Core Trick</div>
<div class="tk">Use debate for <em>evaluation</em>, not generation. Multiple LLM personas judge quality, debate their scores, converge. <span class="ac">Matches human judgments better than any single LLM judge.</span></div>
<div class="lb"><strong>â†’ GlassBox borrows:</strong> Our LLM-as-judge after Round 3 uses debate-as-evaluation. Three agents debating > one agent scoring.</div>
<div class="pg">02 / 16</div></div>

<!-- 03 -->
<div class="paper cg" id="p03"><div class="tb"></div>
<div class="ph"><div class="ib">ğŸ«‚</div><div>
<div class="pt">Society of Mind for LLMs</div>
<div class="pa">(Zhang et al.) Â· ACL 2024 Â· <a href="https://openreview.net/forum?id=ueqTjOcuLc">OpenReview</a></div>
<div class="ps">â­â­â­â­ Personality matters</div></div></div>
<div class="sl">ğŸ­ Analogy</div>
<div class="an">A brainstorm. If everyone is open ("what do you think?"), the group finds better ideas. If one person dominates ("I'm right, shut up"), the group converges on that person's idea, even if it's wrong.</div>
<div class="sl">ğŸ“ Diagram</div>
<div class="dg">Easy-going agents  â†”  Overconfident agents
       â†“                         â†“
  Listen to each other       Bulldoze others
       â†“                         â†“
  âœ… Better answers           âŒ Worse answers
       â†“                         â†“
  Truth emerges              Loudest voice wins</div>
<div class="sl">ğŸ’ The Core Trick</div>
<div class="tk">Agent <em>personality</em> matters as much as capability. Easy-going agents that reference each other by name produce better results. <span class="ac">Overconfident agents kill group accuracy.</span></div>
<div class="lb"><strong>â†’ GlassBox borrows:</strong> Agents say "I agree/disagree with @architect because..." - this referencing-by-name pattern comes directly from this research.</div>
<div class="pg">03 / 16</div></div>

<!-- 04 -->
<div class="paper cg" id="p04"><div class="tb"></div>
<div class="ph"><div class="ib">ğŸŒ³</div><div>
<div class="pt">Tree of Thoughts</div>
<div class="pa">(Yao et al.) Â· NeurIPS 2023 Â· <a href="https://arxiv.org/abs/2305.10601">arXiv:2305.10601</a></div>
<div class="ps">â­â­â­â­â­ System-2 thinking for LLMs</div></div></div>
<div class="sl">ğŸ­ Analogy</div>
<div class="an">Chess. A grandmaster doesn't play the first move that looks good (System-1). They explore multiple sequences, evaluate each, prune bad ones, pick the best path (System-2). This paper gives LLMs that ability.</div>
<div class="sl">ğŸ“ Diagram</div>
<div class="dg">          â”Œâ”€â”€ Thought A1 â†’ A2 â†’ A3 â†’ Score: 0.8 âœ…
Problem â”€â”€â”¤
          â”œâ”€â”€ Thought B1 â†’ B2 âœ— (pruned, dead end)
          â”‚
          â””â”€â”€ Thought C1 â†’ C2 â†’ C3 â†’ Score: 0.6
                                 â†“
               Best path: A1 â†’ A2 â†’ A3</div>
<div class="sl">ğŸ’ The Core Trick</div>
<div class="tk">Instead of one pass (chain-of-thought), explore a <em>tree</em> of reasoning paths. Evaluate each branch. Prune bad ones. <span class="ac">Turns LLMs from "fast and sloppy" into "slow and deliberate."</span></div>
<div class="lb"><strong>â†’ GlassBox borrows:</strong> Multi-round debate is a social version of tree search. Each agent explores a different branch, debate prunes bad paths.</div>
<div class="pg">04 / 16</div></div>

<!-- 05 -->
<div class="paper cb" id="p05"><div class="tb"></div>
<div class="ph"><div class="ib">ğŸ•¸ï¸</div><div>
<div class="pt">EigenTrust: PageRank for Trust</div>
<div class="pa">(Kamvar et al.) Â· WWW 2003 Â· <a href="https://dl.acm.org/doi/10.1145/775152.775242">ACM DL</a></div>
<div class="ps">â­â­â­â­â­ The OG trust algorithm</div></div></div>
<div class="sl">ğŸ­ Analogy</div>
<div class="an">Google PageRank. A website is important if important websites link to it. EigenTrust does the same for people: you're trustworthy if trustworthy people vouch for you. Reputation as linear algebra.</div>
<div class="sl">ğŸ“ Diagram</div>
<div class="dg">Local trust:                   Global trust:
A trusts B: 0.9  â”             â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
C trusts B: 0.7  â”œâ”€eigenvectorâ”€â†’  Global trust(B) = 0.82  â”‚
D trusts B: 0.3  â”˜   of matrix â”‚  (weighted by how trusted â”‚
                                â”‚   A, C, D themselves are) â”‚
                                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜</div>
<div class="sl">ğŸ’ The Core Trick</div>
<div class="tk">Compute <em>global</em> trust from <em>local</em> ratings via eigenvector iteration. Malicious peers can't game the system - their votes are weighted by their own reputation. <span class="ac">Same math as Google, but for trust.</span></div>
<div class="lb"><strong>â†’ GlassBox borrows:</strong> Our EMA trust scoring is a simplified version. Roadmap: full EigenTrust where agents rate each other bidirectionally.</div>
<div class="pg">05 / 16</div></div>

<!-- 06 -->
<div class="paper cb" id="p06"><div class="tb"></div>
<div class="ph"><div class="ib">ğŸ“š</div><div>
<div class="pt">Trust Models Survey</div>
<div class="pa">(Pinyol &amp; Sabater-Mir) Â· ACM Computing Surveys 2013 Â· <a href="https://dl.acm.org/doi/10.1145/2816826">ACM DL</a></div>
<div class="ps">â­â­â­â­ The encyclopedia of trust</div></div></div>
<div class="sl">ğŸ­ Analogy</div>
<div class="an">A Michelin guide, but for trust algorithms. It doesn't invent a new restaurant - it visits every restaurant (trust model) that exists, rates them, tells you which one for which occasion.</div>
<div class="sl">ğŸ“ Diagram</div>
<div class="dg">Trust Models Map:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Cognitive    â†’ "I trust you because I understand you"â”‚
â”‚  Game Theory  â†’ "Cooperation is the rational choice"  â”‚
â”‚  Probabilisticâ†’ "The data says you're reliable"       â”‚
â”‚  Social       â†’ "Others trust you, so I will too"     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      Pick based on: your agents, domain, constraints</div>
<div class="sl">ğŸ’ The Core Trick</div>
<div class="tk">Not a single algorithm - it's <em>the map</em> of the entire design space. Every trust decision has tradeoffs. <span class="ac">This survey tells you which model to pick and why.</span></div>
<div class="lb"><strong>â†’ GlassBox borrows:</strong> We chose EMA (probabilistic) for v0.3.0 simplicity. This survey maps our upgrade path to cognitive/social trust.</div>
<div class="pg">06 / 16</div></div>

<!-- 07 -->
<div class="paper cb" id="p07"><div class="tb"></div>
<div class="ph"><div class="ib">ğŸ§ â¤ï¸</div><div>
<div class="pt">Cognitive vs Emotional Trust</div>
<div class="pa">(Shang et al.) Â· AAAI/ACM AIES 2024 Â· <a href="https://dl.acm.org/doi/10.5555/3716662.3716779">AIES 2024</a></div>
<div class="ps">â­â­â­â­ Trust has two dimensions</div></div></div>
<div class="sl">ğŸ­ Analogy</div>
<div class="an">A surgeon. You trust them cognitively ("top of their class"). But you also need emotional trust ("I feel safe"). Capability without comfort = anxiety. Comfort without capability = negligence. You need both.</div>
<div class="sl">ğŸ“ Diagram</div>
<div class="dg">                  Comfort (Emotional Trust)
                      â†‘
                      â”‚  "Friendly but     âœ… IDEAL
                      â”‚   incompetent"     "Capable AND
                      â”‚   (Clippy)          comfortable"
                      â”‚
                      â”‚  âŒ WORST          "Smart but scary"
                      â”‚  (nothing)          (early ChatGPT)
                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’
                              Capability (Cognitive Trust)</div>
<div class="sl">ğŸ’ The Core Trick</div>
<div class="tk">Humans trust AI on two axes: cognitive ("it's capable") and emotional ("I'm comfortable"). <span class="ac">Showing the reasoning (transparency) boosts emotional trust. You need both.</span></div>
<div class="lb"><strong>â†’ GlassBox borrows:</strong> Our entire thesis. Debate transcripts = emotional trust. Trust scores = cognitive trust. Glass box = both.</div>
<div class="pg">07 / 16</div></div>

<!-- 08 -->
<div class="paper cb" id="p08"><div class="tb"></div>
<div class="ph"><div class="ib">âš–ï¸</div><div>
<div class="pt">LLM-as-a-Judge Survey</div>
<div class="pa">(Li et al.) Â· arXiv 2024 Â· <a href="https://arxiv.org/abs/2411.15594">arXiv:2411.15594</a></div>
<div class="ps">â­â­â­â­ Can LLMs judge other LLMs?</div></div></div>
<div class="sl">ğŸ­ Analogy</div>
<div class="an">Figure skating judges who are also figure skaters. They know the sport, but have biases - they favor their own style, rate the last performer higher, prefer flashy over technically perfect. Useful, but calibrate carefully.</div>
<div class="sl">ğŸ“ Diagram</div>
<div class="dg">Single judge:  LLM â†’ Score (âš ï¸ biased: position, verbosity, self-preference)

Multi-judge:   LLMâ‚ â†’ Scoreâ‚ â”
               LLMâ‚‚ â†’ Scoreâ‚‚ â”œâ†’ Aggregate â†’ Less biased
               LLMâ‚ƒ â†’ Scoreâ‚ƒ â”˜

Debate-judge:  LLMs debate quality â†’ Converge â†’ âœ… Best accuracy</div>
<div class="sl">ğŸ’ The Core Trick</div>
<div class="tk">LLM judges are useful but <em>systematically biased</em>: position bias (prefer first/last), verbosity bias (longer = better), self-preference. <span class="ac">Fix: multiple judges, structured rubrics, debate.</span></div>
<div class="lb"><strong>â†’ GlassBox borrows:</strong> Debate-as-judge avoids single-judge bias. Three agents debating > one agent scoring.</div>
<div class="pg">08 / 16</div></div>

<!-- PAGE BREAK - papers 9-16 continue -->

<!-- 09 -->
<div class="paper cy" id="p09"><div class="tb"></div>
<div class="ph"><div class="ib">ğŸ“</div><div>
<div class="pt">FACTS Grounding Benchmark</div>
<div class="pa">(Google DeepMind) Â· 2024 Â· <a href="https://deepmind.google/blog/facts-grounding-a-new-benchmark-for-evaluating-the-factuality-of-large-language-models/">DeepMind Blog</a></div>
<div class="ps">â­â­â­â­â­ The hallucination ruler</div></div></div>
<div class="sl">ğŸ­ Analogy</div>
<div class="an">A fact-check desk at a newspaper. Every claim must trace to a source. "Crime is up 40%" - "Source? Page? Date?" No source = claim gets cut. This benchmark does that for LLMs.</div>
<div class="sl">ğŸ“ Diagram</div>
<div class="dg">Given: Source document (the truth)
Given: LLM response (claims facts)
                 â†“
FACTS score = % of claims supported by the source
                 â†“
Multi-judge evaluation (multiple LLMs verify each claim)
                 â†“
Score: 0.0 (all hallucinated) â†’ 1.0 (fully grounded)</div>
<div class="sl">ğŸ’ The Core Trick</div>
<div class="tk">First industry-standard benchmark for measuring <em>how well LLMs stick to source material</em>. Uses multiple judges to verify each claim. <span class="ac">The ruler by which all grounding is now measured.</span></div>
<div class="lb"><strong>â†’ GlassBox can borrow:</strong> Future claim verification layer should measure against FACTS-style grounding metrics.</div>
<div class="pg">09 / 16</div></div>

<!-- 10 -->
<div class="paper cy" id="p10"><div class="tb"></div>
<div class="ph"><div class="ib">ğŸœ</div><div>
<div class="pt">MiniCheck: Cheap Fact-Checking</div>
<div class="pa">(Tang et al.) Â· EMNLP 2024 Â· <a href="https://arxiv.org/abs/2404.10774">arXiv:2404.10774</a></div>
<div class="ps">â­â­â­â­ David beats Goliath</div></div></div>
<div class="sl">ğŸ­ Analogy</div>
<div class="an">Airport security. You don't need a PhD detective to check boarding passes. A well-trained guard with a scanner does the job at 1/400th the cost. You don't need GPT-4 to catch lies. A tiny model can do it.</div>
<div class="sl">ğŸ“ Diagram</div>
<div class="dg">GPT-4 fact-check:        MiniCheck (770M params):
  Cost: $$$$$              Cost: $
  Accuracy: 94%            Accuracy: 93.7%
  Speed: slow              Speed: 400x faster
  API dependency: yes      Runs locally: yes</div>
<div class="sl">ğŸ’ The Core Trick</div>
<div class="tk">770M parameter model achieves GPT-4-level fact-checking at <span class="ac">400x lower cost</span>. Trained on 11 unified datasets. You don't need a giant model for verification - you need a specialist.</div>
<div class="lb"><strong>â†’ GlassBox can borrow:</strong> The critic agent could be replaced by a MiniCheck-style specialist - cheaper, faster, runs locally, no API needed.</div>
<div class="pg">10 / 16</div></div>

<!-- 11 -->
<div class="paper cp" id="p11"><div class="tb"></div>
<div class="ph"><div class="ib">âœï¸</div><div>
<div class="pt">Self-Refine</div>
<div class="pa">(Madaan et al.) Â· NeurIPS 2023 Â· <a href="https://arxiv.org/abs/2303.17651">arXiv:2303.17651</a></div>
<div class="ps">â­â­â­â­â­ Edit your own essay</div></div></div>
<div class="sl">ğŸ­ Analogy</div>
<div class="an">Writing an essay. First draft: rough. Re-read, find weak spots, rewrite. Second draft: better. Third draft: polished. You're your own editor. This paper makes LLMs do the same - generate, critique, refine - no training needed.</div>
<div class="sl">ğŸ“ Diagram</div>
<div class="dg">â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Generate â”‚ â”€â”€â†’ â”‚ Critique â”‚ â”€â”€â†’ â”‚  Refine  â”‚
â”‚ (draft)  â”‚     â”‚ (review) â”‚     â”‚ (better) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
                                       â”‚ loop
                                       â†“
                              5-40% improvement</div>
<div class="sl">ğŸ’ The Core Trick</div>
<div class="tk">No training, no fine-tuning, just prompting. LLM generates, critiques its own output, refines. <span class="ac">Free 5-40% improvement across code, math, and writing tasks.</span> The simplest self-improvement loop.</div>
<div class="lb"><strong>â†’ GlassBox borrows:</strong> Our debate is a multi-agent version of Self-Refine. Three agents critique each other instead of one critiquing itself - less echo chamber.</div>
<div class="pg">11 / 16</div></div>

<!-- 12 -->
<div class="paper cp" id="p12"><div class="tb"></div>
<div class="ph"><div class="ib">ğŸ““</div><div>
<div class="pt">Reflexion: Verbal RL</div>
<div class="pa">(Shinn et al.) Â· NeurIPS 2023 Â· <a href="https://arxiv.org/abs/2303.11366">arXiv:2303.11366</a></div>
<div class="ps">â­â­â­â­â­ Learning from failure, in English</div></div></div>
<div class="sl">ğŸ­ Analogy</div>
<div class="an">A student with a mistake journal. After every failed exam: "Got Q3 wrong because I confused velocity with acceleration." Next exam, re-read the journal. No tutoring needed - just honest self-reflection stored in memory.</div>
<div class="sl">ğŸ“ Diagram</div>
<div class="dg">Attempt 1: Try â†’ Fail â†’ "Failed because I missed edge cases"
                                 â†“ store in memory
Attempt 2: Read memory â†’ Try â†’ Fail â†’ "Forgot the base case"
                                            â†“ store
Attempt 3: Read memory â†’ Try with both â†’ âœ… Pass!

Result: 91% on HumanEval (vs 80% baseline). No weight updates.</div>
<div class="sl">ğŸ’ The Core Trick</div>
<div class="tk">Store <em>verbal failure reflections</em> in memory. Agent reads them before retrying. <span class="ac">No gradients, no fine-tuning - just writing down why you failed.</span> 91% pass@1 on HumanEval.</div>
<div class="lb"><strong>â†’ GlassBox can borrow:</strong> Our feedback flywheel's failure log (F1-F15 taxonomy) is exactly this - verbal reflections the agent reads before similar issues.</div>
<div class="pg">12 / 16</div></div>

<!-- 13 -->
<div class="paper cp" id="p13"><div class="tb"></div>
<div class="ph"><div class="ib">ğŸ§¬</div><div>
<div class="pt">Self-Correct via RL</div>
<div class="pa">(Google DeepMind) Â· ICLR 2025 Â· <a href="https://proceedings.iclr.cc/paper_files/paper/2025/file/871ac99fdc5282d0301934d23945ebaa-Paper-Conference.pdf">ICLR 2025</a></div>
<div class="ps">â­â­â­â­ Intrinsic self-correction</div></div></div>
<div class="sl">ğŸ­ Analogy</div>
<div class="an">Learning to catch your own typos. At first you need spell-check (external). After years of writing, you instinctively pause at a word that "looks wrong" - you've internalized the correction. This paper trains that instinct into LLMs.</div>
<div class="sl">ğŸ“ Diagram</div>
<div class="dg">Before (external):
  LLM â†’ wrong answer â†’ human says "wrong" â†’ retry

After (intrinsic, this paper):
  LLM â†’ answer â†’ "wait, that doesn't feel right" â†’ self-corrects
                   â†‘
             Trained via RL to recognize own mistakes</div>
<div class="sl">ğŸ’ The Core Trick</div>
<div class="tk">First method that trains <em>intrinsic</em> self-correction into LLMs via RL. The model improves answers <span class="ac">without any external feedback</span>. Previous papers needed external signals - this one doesn't.</div>
<div class="lb"><strong>â†’ GlassBox can borrow:</strong> Long-term - if debate agents could intrinsically self-correct, we'd need fewer rounds.</div>
<div class="pg">13 / 16</div></div>

<!-- 14 -->
<div class="paper cp" id="p14"><div class="tb"></div>
<div class="ph"><div class="ib">ğŸ—ºï¸</div><div>
<div class="pt">Code Repair as Exploration</div>
<div class="pa">(NeurIPS 2024) Â· <a href="https://proceedings.neurips.cc/paper_files/paper/2024/file/d5c56ec4f69c9a473089b16000d3f8cd-Paper-Conference.pdf">NeurIPS 2024</a></div>
<div class="ps">â­â­â­â­ Don't retry the same fix</div></div></div>
<div class="sl">ğŸ­ Analogy</div>
<div class="an">Lost your keys. Do you search the same pocket 3 times (exploit)? Or check the table, coat, drawer (explore)? Searching the same place repeatedly is insane - but that's exactly what coding agents do when they retry the same broken fix.</div>
<div class="sl">ğŸ“ Diagram</div>
<div class="dg">âŒ BAD (exploit):                âœ… GOOD (explore):
Attempt 1: Fix A â†’ fail          Attempt 1: Fix A â†’ fail
Attempt 2: Fix A â†’ fail          Attempt 2: Fix B â†’ fail
Attempt 3: Fix A â†’ fail          Attempt 3: Fix C â†’ pass!
     â†“                                 â†“
  Same bug, 3 times              Different strategies, found it</div>
<div class="sl">ğŸ’ The Core Trick</div>
<div class="tk">Frame code repair as a <em>tree search</em> with exploration-exploitation tradeoff. Better expansion policies â†’ better fixes. <span class="ac">Agents that explore diverse strategies fix 2x more bugs.</span></div>
<div class="lb"><strong>â†’ GlassBox must borrow:</strong> Issue #18 failed exactly this way - agent retried same approach 3 times. REQ-07 now mandates different strategies per retry.</div>
<div class="pg">14 / 16</div></div>

<!-- 15 -->
<div class="paper cr" id="p15"><div class="tb"></div>
<div class="ph"><div class="ib">ğŸ›ï¸</div><div>
<div class="pt">AI Safety via Debate</div>
<div class="pa">(Irving, Christiano &amp; Amodei) Â· 2018 Â· <a href="https://arxiv.org/abs/1805.00899">arXiv:1805.00899</a></div>
<div class="ps">â­â­â­â­â­ The paper that started it all</div></div></div>
<div class="sl">ğŸ­ Analogy</div>
<div class="an">The legal system. You (the judge) can't investigate every crime yourself. Two lawyers compete to convince you. Because it's adversarial, lies get exposed. It works even though the judge is weaker than the lawyers.</div>
<div class="sl">ğŸ“ Diagram</div>
<div class="dg">        Human judge (limited, can't verify everything)
                         â†‘
          Agent A â†â”€ debate â”€â†’ Agent B
          (argues X)             (argues Y)
                         â†“
         Zero-sum game: lying is punished
         Truth is the Nash equilibrium
                         â†“
         Human gets correct answer despite being weaker</div>
<div class="sl">ğŸ’ The Core Trick</div>
<div class="tk">Two AIs debate to help a <em>weak human judge</em> - even on tasks too complex for the human alone. <span class="ac">Debate as a zero-sum game where truth is the Nash equilibrium.</span> Lying agents get caught by the opponent.</div>
<div class="lb"><strong>â†’ GlassBox borrows:</strong> This IS our foundational philosophy. Debate = safety. Transparency = trust. The human sees the reasoning, not just the answer.</div>
<div class="pg">15 / 16</div></div>

<!-- 16 -->
<div class="paper cr" id="p16"><div class="tb"></div>
<div class="ph"><div class="ib">ğŸ“œ</div><div>
<div class="pt">Constitutional AI</div>
<div class="pa">(Bai et al., Anthropic) Â· 2022 Â· <a href="https://arxiv.org/abs/2212.08073">arXiv:2212.08073</a></div>
<div class="ps">â­â­â­â­â­ Rules instead of humans</div></div></div>
<div class="sl">ğŸ­ Analogy</div>
<div class="an">Raising a child. Option A: hire a nanny to watch every move (RLHF - expensive, doesn't scale). Option B: teach principles - "be kind, tell the truth" - and let them self-correct (Constitutional AI - scales infinitely).</div>
<div class="sl">ğŸ“ Diagram</div>
<div class="dg">RLHF (old way):                Constitutional AI (this paper):
Human labels: "harmful"        Principles: "Be helpful, harmless, honest"
â†’ expensive, slow              â†’ free, instant
â†’ 50K+ annotations            â†’ 0 annotations
â†’ doesn't scale               â†’ scales infinitely
                                        â†“
                               AI: "Is my response harmful?"
                               AI: "Let me fix it per principles"
                                        â†“
                               RLAIF (AI feedback replaces human feedback)</div>
<div class="sl">ğŸ’ The Core Trick</div>
<div class="tk">Replace human feedback (RLHF) with AI self-judgment against a <em>constitution</em> of principles (RLAIF). <span class="ac">Zero human labels for safety alignment.</span> AI self-improves by asking "does this follow my principles?"</div>
<div class="lb"><strong>â†’ GlassBox borrows:</strong> Agent prompts act as a mini-constitution: "@architect: think long-term", "@critic: find failures." Principles guide behavior without human-in-the-loop per turn.</div>
<div class="pg">16 / 16</div></div>

<!-- CHECKLIST PAGE -->
<div class="paper ck" id="checklist"><div class="tb"></div>
<div class="ck-t">What GlassBox Borrows - and What's Next</div>
<div class="ck-s">âœ… = already implemented in v0.3.0 &nbsp;&nbsp; ğŸ”² = on the roadmap</div>

<div class="ck-row"><div class="ck-chk">âœ…</div><div class="ck-paper">01 Multi-Agent Debate</div><div class="ck-what">3-round debate: Position â†’ Reaction â†’ Convergence</div></div>
<div class="ck-row"><div class="ck-chk">âœ…</div><div class="ck-paper">02 ChatEval</div><div class="ck-what">Debate-as-evaluation after Round 3 (LLM judge)</div></div>
<div class="ck-row"><div class="ck-chk">âœ…</div><div class="ck-paper">03 Society of Mind</div><div class="ck-what">Agents reference each other by @name, have distinct personalities</div></div>
<div class="ck-row"><div class="ck-chk">âœ…</div><div class="ck-paper">04 Tree of Thoughts</div><div class="ck-what">Debate as social tree search (each agent = different branch)</div></div>
<div class="ck-row"><div class="ck-chk">âœ…</div><div class="ck-paper">05 EigenTrust</div><div class="ck-what">EMA trust scoring (simplified). Scores persist in SQLite.</div></div>
<div class="ck-row"><div class="ck-chk">âœ…</div><div class="ck-paper">06 Trust Survey</div><div class="ck-what">Chose probabilistic trust (EMA) for v0.3.0</div></div>
<div class="ck-row"><div class="ck-chk">âœ…</div><div class="ck-paper">07 Cognitive/Emotional</div><div class="ck-what">Transcripts = emotional trust, scores = cognitive trust</div></div>
<div class="ck-row"><div class="ck-chk">âœ…</div><div class="ck-paper">08 LLM-as-Judge</div><div class="ck-what">Multi-agent debate avoids single-judge bias</div></div>
<div class="ck-row"><div class="ck-chk">ğŸ”²</div><div class="ck-paper">09 FACTS Grounding</div><div class="ck-what">Claim verification layer (roadmap item)</div></div>
<div class="ck-row"><div class="ck-chk">ğŸ”²</div><div class="ck-paper">10 MiniCheck</div><div class="ck-what">Replace critic with lightweight specialist model</div></div>
<div class="ck-row"><div class="ck-chk">âœ…</div><div class="ck-paper">11 Self-Refine</div><div class="ck-what">Debate IS multi-agent Self-Refine (generate â†’ critique â†’ refine)</div></div>
<div class="ck-row"><div class="ck-chk">ğŸ”²</div><div class="ck-paper">12 Reflexion</div><div class="ck-what">Failure log (F1-F15) as verbal reflections for agent memory</div></div>
<div class="ck-row"><div class="ck-chk">ğŸ”²</div><div class="ck-paper">13 Self-Correct RL</div><div class="ck-what">Intrinsic self-correction (long-term, needs fine-tuning)</div></div>
<div class="ck-row"><div class="ck-chk">ğŸ”²</div><div class="ck-paper">14 Code Repair</div><div class="ck-what">Exploration-exploitation retry strategy (REQ-07)</div></div>
<div class="ck-row"><div class="ck-chk">âœ…</div><div class="ck-paper">15 Safety via Debate</div><div class="ck-what">Core philosophy: debate = safety, transparency = trust</div></div>
<div class="ck-row"><div class="ck-chk">âœ…</div><div class="ck-paper">16 Constitutional AI</div><div class="ck-what">Agent prompts as mini-constitution (system prompts with principles)</div></div>

<div style="margin-top:32px;padding-top:16px;border-top:1px solid #1e293b;font-size:.82rem;color:#64748b">
<strong style="color:#4ade80">Score: 10/16 borrowed</strong> &nbsp;Â·&nbsp; 6 more on the roadmap &nbsp;Â·&nbsp; Each one is a GitHub issue waiting to happen
</div>
<div class="pg">âœ… / 16</div></div>

</body>
</html>
