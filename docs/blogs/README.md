# Blogs & External References

Curated blogs, articles, and industry reports that inform GlassBox AI's approach to transparent multi-agent systems.

---

## Why AI Agents Fail

| Title | Source | Link |
|-------|--------|------|
| Agentic AI in 2025: Why 90% of Implementations Fail | Beam AI | [beam.ai](https://beam.ai/agentic-insights/agentic-ai-in-2025-why-90-of-implementations-fail-(and-how-to-be-the-10-)) |
| Why Multi-Agent LLM Systems Fail (and How to Fix Them) | Augment Code | [augmentcode.com](https://www.augmentcode.com/guides/why-multi-agent-llm-systems-fail-and-how-to-fix-them) |
| Debugging AI-Generated Code: 8 Failure Patterns & Fixes | Augment Code | [augmentcode.com](https://www.augmentcode.com/guides/debugging-ai-generated-code-8-failure-patterns-and-fixes) |
| State of AI Agents in 2025: A Technical Analysis | Carl Rannaberg / Medium | [medium.com](https://carlrannaberg.medium.com/state-of-ai-agents-in-2025-5f11444a5c78) |
| Cognition SWE-bench Technical Report (Devin) | Cognition AI | [cognition.ai](https://cognition.ai/blog/swe-bench-technical-report) |

## Multi-Agent Debate & Trust

| Title | Source | Link |
|-------|--------|------|
| AI Safety via Debate (original blog) | OpenAI | [openai.com](https://openai.com/research/debate) |
| Constitutional AI blog | Anthropic | [anthropic.com](https://www.anthropic.com/research/constitutional-ai-harmlessness-from-ai-feedback) |
| FACTS Grounding benchmark | Google DeepMind | [deepmind.google](https://deepmind.google/blog/facts-grounding-a-new-benchmark-for-evaluating-the-factuality-of-large-language-models/) |

## AI Code Security

| Title | Source | Link |
|-------|--------|------|
| The Most Common Security Vulnerabilities in AI-Generated Code | Endor Labs | [endorlabs.com](https://www.endorlabs.com/learn/the-most-common-security-vulnerabilities-in-ai-generated-code) |
| 8 AI Code Generation Mistakes Devs Must Fix | Futurism/Vocal | [vocal.media](https://vocal.media/futurism/8-ai-code-generation-mistakes-devs-must-fix-to-win-2026) |

## Benchmarks & Evaluations

| Title | Source | Link |
|-------|--------|------|
| SWE-Bench Pro quick review | Liner | [liner.com](https://liner.com/review/swebench-pro-can-ai-agents-solve-longhorizon-software-engineering-tasks) |
| AI Agent Benchmark comparison | GitHub | [github.com/murataslan1](https://github.com/murataslan1/ai-agent-benchmark) |
| AI Agentic Programming: A Survey | arXiv 2025 | [arXiv:2508.11126](https://arxiv.org/html/2508.11126v1) |
